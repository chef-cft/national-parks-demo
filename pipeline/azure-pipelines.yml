pool: henkhaus-forest

variables:
  - group: tf-backend-sa-pipeline
stages:



# STAGE 0 Setup
- stage: Setup
  displayName: Setup 
  jobs:
  - job: SetupVariables
    displayName: Setup Variables
    
    steps:
    - task: Bash@3
      inputs:
        targetType: 'inline'
        script: |
          mkdir -p $(Pipeline.Workspace)/variables/national-parks-validator
      displayName: Create Variable Store

    - task: Bash@3
      inputs:
        targetType: 'inline'
        script: |
          rm -rf $(Pipeline.Workspace)/variables/national-parks-validator/*
      displayName: Clean Variables

   

### STAGE 1 Build Package(s)
- stage: Build
  displayName: Build 
  condition: eq(variables.runBuild, true)
  dependsOn: Setup
  jobs:
  - job: Build_National_Parks
    displayName: Build National Parks
    
    steps:

    - task: Bash@3
      inputs:
        targetType: 'inline'
        script: |
                  sudo yum -y install https://packages.endpoint.com/rhel/7/os/x86_64/endpoint-repo-1.7-1.x86_64.rpm
                  sudo yum install -y git unzip
                  sudo yum install epel-release -y
                  sudo yum install jq -y
      displayName: 'Install Package Dependencies'
    
    - task: vsts-habitat-install@3
      displayName: 'Install Habitat'

    - task: vsts-habitat-signing-key@3
      inputs:
        habitatOrigin: 'Habitat-Chef-SA-Pipeline'
        taskAction: 'install'
      displayName: 'Install Signing Origin Key'

    - task: vsts-habitat-build@3
      inputs:
        habitatOrigin: 'Habitat-Chef-SA-Pipeline'
        habitatSrcPath: '$(Build.SourcesDirectory)'
        habitatPlanContext: 'habitat'
      env:
        HAB_LICENSE: accept-no-persist
      displayName: 'Build Habitat Package'
    
    - task: vsts-habitat-expose-habitat-build-vars@3
      inputs:
        habitatLastBuildEnvPath: '$(Build.SourcesDirectory)/results'
        habitatSetBuildNumber: true
        habitatImageNamesFilename: '$(System.DefaultWorkingDirectory)/image.names'
      displayName: 'Expose Habitat Build Variables'

    - publish: $(System.DefaultWorkingDirectory)/results
      artifact: hart
      displayName: 'Publish Artifact'
    
    - script: |
              source $(System.DefaultWorkingDirectory)/results/last_build.env
              echo "##vso[task.setvariable variable=pkg_artifact]$pkg_artifact"
      displayName: 'Publish Artifact Name'

    - task: vsts-habitat-pkg-upload@3
      displayName: 'Package Upload'
      inputs:
        habitatOrigin: 'Habitat-Chef-SA-Pipeline'
        habitatPackagePath: '$(System.DefaultWorkingDirectory)/results/$(pkg_artifact)'
        habitatPackageChannel: 'testing'
      env:
        HAB_LICENSE: accept-no-persist
   


### STAGE 2 Deploy Automate
- stage: Deploy
  displayName: Deploy 
  dependsOn: Build
  condition: eq(variables.runDeploy, true)
  jobs:
  - job: Deploy_Automate
    displayName: Deploy Automate
    
    steps:

    - task: Bash@3
      inputs:
        targetType: 'inline'
        script: |
                  sudo yum -y install https://packages.endpoint.com/rhel/7/os/x86_64/endpoint-repo-1.7-1.x86_64.rpm
                  sudo yum install -y git unzip
                  sudo yum install epel-release -y
                  sudo yum install jq -y
      displayName: 'Install Package Dependencies'

    - task: TerraformInstaller@0
      inputs:
        terraformVersion: '0.12.24'
      displayName: "Install Terraform"

    - task: DownloadSecureFile@1
      name: tfAutomateVarsFile
      inputs:
        secureFile: 'automate-pipeline.tfvars'
      displayName: 'Download automate-pipeline.tfvars'
    
    - task: DownloadSecureFile@1
      name: awsInstanceKey
      inputs:
        secureFile: 'demo-validator-us-east-1.pem'
      displayName: 'Download AWS Instance Key'
    
    - task: Bash@3  
      inputs:
        targetType: 'inline'
        script: |
                  sudo chmod 600 $(awsInstanceKey.secureFilePath)
      displayName: 'Update AWS Instance Key Permissions'
    
    - task: TerraformTaskV1@0
      displayName: "Terraform Init"
      inputs:
        provider: 'aws'
        command: 'init'
        workingDirectory: '$(System.DefaultWorkingDirectory)/terraform/chef-automate/aws'
        backendServiceAWS: 'AWS-ADO-Pipeline'
        backendAWSBucketName: '$(bucketName)'
        backendAWSKey: '$(keyAutomate)'
      
    - task: TerraformTaskV1@0
      displayName: "Terraform Apply"
      name: automateApply
      inputs:
        provider: 'aws'
        command: 'apply'
        workingDirectory: '$(System.DefaultWorkingDirectory)/terraform/chef-automate/aws'
        commandOptions: '-var-file=$(tfAutomateVarsFile.secureFilePath) -var "aws_key_pair_file=$(awsInstanceKey.secureFilePath)"'
        environmentServiceNameAWS: 'AWS-ADO-Pipeline'
    
    - task: Bash@3
      inputs:
        targetType: 'inline'
        script: |
                  cat $(automateApply.jsonOutputVariablesPath) > $(Pipeline.Workspace)/variables/national-parks-validator/TF_OUTPUT_AUTOMATE
      displayName: 'Store Terraform Outputs'


  - job: Deploy_National_Parks
    dependsOn: Deploy_Automate
    displayName: Deploy National Parks
    
    steps:
    - task: Bash@3
      inputs:
        targetType: 'inline'
        script: |
                  sudo yum -y install https://packages.endpoint.com/rhel/7/os/x86_64/endpoint-repo-1.7-1.x86_64.rpm
                  sudo yum install -y git unzip
                  sudo yum install epel-release -y
                  sudo yum install jq -y
      displayName: 'Install Package Dependencies'

    - task: TerraformInstaller@0
      inputs:
        terraformVersion: '0.12.24'
      displayName: "Install Terraform"
    - task: DownloadSecureFile@1
      name: tfNatParksVarsFile
      inputs:
        secureFile: 'nat-parks-pipeline.tfvars'
      displayName: 'Download nat-parks-pipeline.tfvars'

    - task: DownloadSecureFile@1
      name: awsInstanceKey
      inputs:
        secureFile: 'demo-validator-us-east-1.pem'
      displayName: 'Download AWS Instance Key'
    
    - task: Bash@3
      inputs:
        targetType: 'inline'
        script: |
                  sudo chmod 600 $(awsInstanceKey.secureFilePath)
      displayName: 'Update AWS Instance Key Permissions'

    - task: TerraformTaskV1@0
      inputs:
        provider: 'aws'
        command: 'init'
        workingDirectory: 'terraform/aws'
        backendServiceAWS: 'AWS-ADO-Pipeline'
        backendAWSBucketName: '$(bucketName)'
        backendAWSKey: '$(keyNationalParks)'
      displayName: "Terraform Init"

    - task: TerraformTaskV1@0
      name: nationalParksApply
      inputs:
        provider: 'aws'
        command: 'apply'
        workingDirectory: '$(System.DefaultWorkingDirectory)/terraform/aws'
        commandOptions: '-var-file=$(tfNatParksVarsFile.secureFilePath) -var "aws_key_pair_file=$(awsInstanceKey.secureFilePath)"'
        environmentServiceNameAWS: 'AWS-ADO-Pipeline'
      displayName: "Terraform Apply"
    
    - task: Bash@3
      inputs:
        targetType: 'inline'
        script: |
                  cat $(nationalParksApply.jsonOutputVariablesPath) > $(Pipeline.Workspace)/variables/national-parks-validator/TF_OUTPUT_NATIONAL_PARKS
      displayName: 'Store Terraform Outputs'



### STAGE 3 Test
- stage: Test 
  displayName: Test
  dependsOn: Deploy
  variables:
    a2AdminUser: ""
    a2AdminPassword: ""
    a2Token: ""
    a2Url: ""
    chefAutomatePublicIp: ""
    chefAutomateServerPublicR53Dns: ""
    haproxyPublicIp: ""
    mongodbPublicIp: ""
    nationalParksPublicIp: ""
    permanentPeerPublicIp: ""

  condition: eq(variables.runTest, true)
  jobs:
  - job: inspec_testing
    displayName: InSpec Testing

    steps:

    - task: Bash@3
      inputs:
        targetType: 'inline'
        script: |
                  # Load Automate Outputs
                  a2_admin=$(cat $(Pipeline.Workspace)/variables/national-parks-validator/TF_OUTPUT_AUTOMATE | jq .a2_admin.value -r )
                  echo "##vso[task.setvariable variable=a2AdminUser]$a2_admin"

                  a2_admin_password=$(cat $(Pipeline.Workspace)/variables/national-parks-validator/TF_OUTPUT_AUTOMATE | jq .a2_admin_password.value -r )
                  echo "##vso[task.setvariable variable=a2AdminPassword]$a2_admin_password"

                  a2_token=$(cat $(Pipeline.Workspace)/variables/national-parks-validator/TF_OUTPUT_AUTOMATE | jq .a2_token.value -r )
                  echo "##vso[task.setvariable variable=a2Token]$a2_token"

                  a2_url=$(cat $(Pipeline.Workspace)/variables/national-parks-validator/TF_OUTPUT_AUTOMATE | jq .a2_url.value -r )
                  echo "##vso[task.setvariable variable=a2Url]$a2_url"
                  
                  chef_automate_public_ip=$(cat $(Pipeline.Workspace)/variables/national-parks-validator/TF_OUTPUT_AUTOMATE | jq .chef_automate_public_ip.value -r )
                  echo "##vso[task.setvariable variable=chefAutomatePublicIp]$chef_automate_public_ip"
                  
                  chef_automate_server_public_r53_dns=$(cat $(Pipeline.Workspace)/variables/national-parks-validator/TF_OUTPUT_AUTOMATE | jq .chef_automate_server_public_r53_dns.value -r )
                  echo "##vso[task.setvariable variable=chefAutomateServerPublicR53Dns]$chef_automate_server_public_r53_dns"
                  
                  # Load National Parks Outputs
                  haproxy_public_ip=$(cat $(Pipeline.Workspace)/variables/national-parks-validator/TF_OUTPUT_NATIONAL_PARKS | jq .haproxy_public_ip.value -r)
                  echo "##vso[task.setvariable variable=haproxyPublicIp]$haproxy_public_ip"

                  mongodb_public_ip=$(cat $(Pipeline.Workspace)/variables/national-parks-validator/TF_OUTPUT_NATIONAL_PARKS | jq .mongodb_public_ip.value -r)
                  echo "##vso[task.setvariable variable=mongodbPublicIp]$mongodb_public_ip"

                  national_parks_public_ip=$(cat $(Pipeline.Workspace)/variables/national-parks-validator/TF_OUTPUT_NATIONAL_PARKS | jq .national_parks_public_ip.value -r)
                  echo "##vso[task.setvariable variable=nationalParksPublicIp]$national_parks_public_ip"

                  permanent_peer_public_ip=$(cat $(Pipeline.Workspace)/variables/national-parks-validator/TF_OUTPUT_NATIONAL_PARKS | jq .permanent_peer_public_ip.value -r)
                  echo "##vso[task.setvariable variable=permanentPeerPublicIp]$permanent_peer_public_ip"
      displayName: 'Parse Terraform Outputs'

    - task: Bash@3
      inputs:
        targetType: 'inline'
        script: |
                  echo "a2AdminUser: $(a2AdminUser)"
                  echo "a2AdminPassword: $(a2AdminPassword)"
                  echo "a2Token: $(a2Token)"
                  echo "a2Url: $(a2Url)"
                  echo "chefAutomatePublicIp: $(chefAutomatePublicIp)"
                  echo "chefAutomateServerPublicR53Dns: $(chefAutomateServerPublicR53Dns)"
                  echo "haproxyPublicIp: $(haproxyPublicIp)"
                  echo "mongodbPublicIp: $(mongodbPublicIp)"
                  echo "nationalParksPublicIp: $(nationalParksPublicIp)"
                  echo "permanentPeerPublicIp: $(permanentPeerPublicIp)"
      displayName: 'Read Terraform Outputs'



### STAGE 4 Clean Up
- stage: Clean_Up
  displayName: Clean Up
  condition: eq(variables.runCleanUp, true)
  jobs:
  - job: Clean_Up_Automate
    dependsOn: Clean_Up_National_Parks
    displayName: Clean Up Automate
    
    steps:
    - task: Bash@3
      inputs:
        targetType: 'inline'
        script: |
                  sudo yum -y install https://packages.endpoint.com/rhel/7/os/x86_64/endpoint-repo-1.7-1.x86_64.rpm
                  sudo yum install -y git unzip
                  sudo yum install epel-release -y
                  sudo yum install jq -y
      displayName: 'Install Package Dependencies'
    
    - task: DownloadSecureFile@1
      name: tfAutomateVarsFile
      inputs:
        secureFile: 'automate-pipeline.tfvars'
      displayName: 'Download automate-pipeline.tfvars'
    
    - task: DownloadSecureFile@1
      name: awsInstanceKey
      inputs:
        secureFile: 'demo-validator-us-east-1.pem'
      displayName: 'Download AWS Instance Key'

    - task: TerraformInstaller@0
      inputs:
        terraformVersion: '0.12.24'
      displayName: "Install Terraform"

    - task: TerraformTaskV1@0
      displayName: "Terraform Init"
      inputs:
        provider: 'aws'
        command: 'init'
        workingDirectory: '$(System.DefaultWorkingDirectory)/terraform/chef-automate/aws'
        backendServiceAWS: 'AWS-ADO-Pipeline'
        backendAWSBucketName: '$(bucketName)'
        backendAWSKey: '$(keyAutomate)'

    - task: TerraformTaskV1@0
      inputs:
        provider: 'aws'
        command: 'destroy'
        workingDirectory: '$(System.DefaultWorkingDirectory)/terraform/chef-automate/aws'
        commandOptions: '-var-file=$(tfAutomateVarsFile.secureFilePath) -var "aws_key_pair_file=$(awsInstanceKey.secureFilePath)"'
        environmentServiceNameAWS: 'AWS-ADO-Pipeline'
      displayName: "Terraform Destroy"

  - job: Clean_Up_National_Parks
    displayName: Clean Up National Parks
    
    steps:
    
    - task: Bash@3
      inputs:
        targetType: 'inline'
        script: |
                  sudo yum -y install https://packages.endpoint.com/rhel/7/os/x86_64/endpoint-repo-1.7-1.x86_64.rpm
                  sudo yum install -y git unzip
                  sudo yum install epel-release -y
                  sudo yum install jq -y
      displayName: 'Install Package Dependencies'
    
    - task: DownloadSecureFile@1
      name: tfNatParksVarsFile
      inputs:
        secureFile: 'nat-parks-pipeline.tfvars'
      displayName: 'Download nat-parks-pipeline.tfvars'
    
    - task: DownloadSecureFile@1
      name: awsInstanceKey
      inputs:
        secureFile: 'demo-validator-us-east-1.pem'
      displayName: 'Download AWS Instance Key'

    - task: TerraformInstaller@0
      inputs:
        terraformVersion: '0.12.24'
      displayName: "Install Terraform"

    - task: TerraformTaskV1@0
      displayName: "Terraform Init"
      inputs:
        provider: 'aws'
        command: 'init'
        workingDirectory: '$(System.DefaultWorkingDirectory)/terraform/aws'
        backendServiceAWS: 'AWS-ADO-Pipeline'
        backendAWSBucketName: '$(bucketName)'
        backendAWSKey: '$(keyNationalParks)'

    - task: TerraformTaskV1@0
      inputs:
        provider: 'aws'
        command: 'destroy'
        workingDirectory: '$(System.DefaultWorkingDirectory)/terraform/aws'
        commandOptions: '-var-file=$(tfNatParksVarsFile.secureFilePath) -var "aws_key_pair_file=$(awsInstanceKey.secureFilePath)"'
        environmentServiceNameAWS: 'AWS-ADO-Pipeline'
      displayName: "Terraform Destroy"
